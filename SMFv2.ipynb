{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackcaer/SMF-training/blob/main/SMFv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oIr08PCme-MX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Initializing\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd  # https://github.com/microsoft/LightGBM/issues/5914\n",
        "\n",
        "!pip install lightgbm #--config-settings=cmake.define.USE_GPU=ON\n",
        "\n",
        "!pip install scikit-optimize\n",
        "\n",
        "import lightgbm as lgb\n",
        "from IPython.display import display\n",
        "\n",
        "#import os\n",
        "import json\n",
        "#import time\n",
        "import gc\n",
        "import random\n",
        "import psutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import traceback\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "\n",
        "from google.colab import files\n",
        "from sys import getsizeof\n",
        "from time import time\n",
        "import pprint\n",
        "#import joblib\n",
        "\n",
        "from collections import defaultdict, Counter\n",
        "from itertools import combinations\n",
        "\n",
        "from sklearn import preprocessing\n",
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import root_mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,median_absolute_error\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit#, GridSearchCV\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "#from skopt import BayesSearchCV\n",
        "#from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
        "#from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "#from scipy.fftpack import fft\n",
        "#from scipy.stats import zscore\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "!pip install optuna\n",
        "!pip install optuna-integration[lightgbm]\n",
        "import optuna\n",
        "from optuna.integration import LightGBMPruningCallback\n",
        "\n",
        "from torch.cuda import get_device_name,is_available\n",
        "#from os import cpu_count\n",
        "\n",
        "#print(f\"Liczba rdzeni procesora: {cpu_count()} (realnych 2x mniej prawdopodobnie)\")\n",
        "gpu_available = is_available()\n",
        "\n",
        "if gpu_available:\n",
        "    print(\"GPU avalibe.\")\n",
        "    print(\"Name of GPU:\", get_device_name(0))\n",
        "else:\n",
        "    print(\"GPU is not avalibe.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MYPEGa3cfjx1"
      },
      "outputs": [],
      "source": [
        "#@title Constants\n",
        "\n",
        "ITEMS_PHSM_JSON = '/content/drive/My Drive/SMF_files/items_phsm.json'\n",
        "ITEMS_PHSM_JSON_TEST = '/content/drive/My Drive/SMF_files/items_phsm_test.json'\n",
        "\n",
        "PLAYER_COUNT_JSON = '/content/drive/My Drive/SMF_files/rust_player_count_interpolated.json'\n",
        "\n",
        "SPIKES_TH=2\n",
        "SPIKES_TH_TEST=1.5\n",
        "SPIKES_PATH='/content/drive/My Drive/SMF_files/spikes_correction.csv'\n",
        "SPIKES_PATH_TEST='/content/drive/My Drive/SMF_files/spikes_correction_test.csv'\n",
        "\n",
        "MODEL_SAVES_PATH='/content/drive/MyDrive/SMF_files/model_saves'\n",
        "OPT_SAVES_PATH=\"/content/drive/MyDrive/SMF_files/opt_saves/\"\n",
        "\n",
        "ITEMS_TO_EXCLUDE=['Metal Tree Door',]#'No Mercy Revolver - E Class','Neon Dragon Garage Door','Zipper Face'] # 'Metal Tree Door' - one of the rarest items in the game, very few sales since 2018\n",
        "\n",
        "N_SPLITS = 5\n",
        "TEST_MODE = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Mey58tCLfj0H"
      },
      "outputs": [],
      "source": [
        "#@title Helpers 1\n",
        "def get_learning_summary(y_pred_train, y_train, y_pred_test, y_test, y_pred_naive, label=\"[no label]\"):\n",
        "  \"\"\" Returns dataframe with metrics\"\"\"\n",
        "\n",
        "  results = {\n",
        "      \"Metric\": [\"Accuracy\", \"RMSE\", \"MAE\", \"MAPE\", \"Max Error\", \"Median Absolute Error\"],\n",
        "      \"Train\": calc_accuracy(y_pred_train, y_train, \"Train accuracy:\"),\n",
        "      \"Valid\": calc_accuracy(y_pred_test, y_test, \"Validation accuracy:\"),\n",
        "      \"Naive\": calc_accuracy(y_pred_naive, y_test, \"Naive accuracy:\")\n",
        "  }\n",
        "\n",
        "  #display(df)\n",
        "  return pd.DataFrame(results)\n",
        "\n",
        "def calc_accuracy(pred, actual, label=\"\"):\n",
        "  \"\"\" Returns accuracy metrics: accuracy, rmse, mae, mape, max_error, median_absolute_error \"\"\"\n",
        "  N=3\n",
        "  errors = np.abs(pred - actual)\n",
        "  accuracy = round(100 * (1 - np.mean(errors / actual)), N)\n",
        "  max_error = round(np.max(errors), N)\n",
        "  std_deviation = round(np.std(errors), N)\n",
        "  mae = round(np.mean(errors), N)\n",
        "  median_absolute_error = round(np.median(errors), N)\n",
        "  mape = round(mean_absolute_percentage_error(actual, pred), N)\n",
        "  rmse = round(root_mean_squared_error(actual, pred), N)\n",
        "\n",
        "  return accuracy, rmse, mae, mape, max_error, median_absolute_error\n",
        "\n",
        "def print_importances(model,start=0,print_tab=False,name=\"\",figsize=(10, 18),importance_type='gain',end=-1):\n",
        "  importance = model.feature_importance(importance_type=importance_type)  # 'split' lub 'gain'\n",
        "  feature_names = model.feature_name()\n",
        "\n",
        "  trim=0\n",
        "  importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
        "  importance_df = importance_df.sort_values(by='Importance', ascending=False)[start:end]\n",
        "\n",
        "  # Wizualizacja\n",
        "  print(f\"Trimmed first {trim} features to see better\")\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
        "  plt.xlabel('Importance')\n",
        "  plt.title(f'Feature Importance {name}')\n",
        "  plt.style.use('dark_background')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  if print_tab:\n",
        "    display(importance_df)\n",
        "\n",
        "def aggregate_pricehistories(pricehistories):\n",
        "    interpolated_histories = []\n",
        "    max_date = max(df.index.max() for df in pricehistories)\n",
        "    for df in pricehistories:\n",
        "        df_resampled = df.resample('D').interpolate(method='linear')\n",
        "        full_date_range = pd.date_range(start=df_resampled.index.min(), end=max_date, freq='D')\n",
        "        df_reindexed = df_resampled.reindex(full_date_range)\n",
        "        df_filled = df_reindexed.ffill()\n",
        "\n",
        "        interpolated_histories.append(df_filled)\n",
        "\n",
        "    all_data = pd.concat(interpolated_histories)\n",
        "\n",
        "    sum = all_data.groupby(all_data.index).sum()\n",
        "    med = all_data.groupby(all_data.index).median()\n",
        "    mean = all_data.groupby(all_data.index).mean()\n",
        "\n",
        "    plot_pricehistory([med[:],mean[:]],['med','mean'],\"Test\")\n",
        "    plot_pricehistory([sum[:]],['sum'],\"Test\",1)\n",
        "    return sum,med,mean\n",
        "\n",
        "def col_from_idx(df,idx_name,pos=None):\n",
        "  df[idx_name] = df.index.get_level_values(idx_name)\n",
        "  if pos is not None:\n",
        "    cols = df.columns.tolist()\n",
        "    cols.insert(pos, cols.pop(cols.index(idx_name)))\n",
        "    df = df[cols]\n",
        "\n",
        "def plot_pricehistory(pricehistories: list, labels: list, title, day_interval=30, relative_x_axis=False, figsize=(16, 6)):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for i in range(len(pricehistories)):\n",
        "        if relative_x_axis:\n",
        "            days_from_start = (pricehistories[i].index - pricehistories[i].index[0]).days\n",
        "\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=days_from_start,\n",
        "                y=pricehistories[i].values,\n",
        "                mode='lines',\n",
        "                name=labels[i]\n",
        "            ))\n",
        "        else:\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=pricehistories[i].index,\n",
        "                y=pricehistories[i].values,\n",
        "                mode='lines',\n",
        "                name=labels[i]\n",
        "            ))\n",
        "\n",
        "    if relative_x_axis:\n",
        "        fig.update_xaxes(title_text='Days from Start', tickvals=days_from_start[::day_interval])\n",
        "    else:\n",
        "        fig.update_xaxes(title_text='Date', tickformat='%Y-%m-%d', dtick=f'{day_interval*86400000}')  # dtick w milisekundach\n",
        "\n",
        "    fig.update_yaxes(title_text='Price')\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis=dict(\n",
        "            tickangle=45,\n",
        "            showgrid=True,\n",
        "            gridcolor='gray',\n",
        "            gridwidth=0.5\n",
        "        ),\n",
        "        yaxis=dict(\n",
        "            showgrid=True,\n",
        "            gridcolor='gray',\n",
        "            gridwidth=0.5\n",
        "        ),\n",
        "        template='plotly_dark',\n",
        "        legend=dict(\n",
        "            x=0.01, y=0.99,\n",
        "            bordercolor=\"Black\",\n",
        "            borderwidth=1\n",
        "        ),\n",
        "        autosize=False,\n",
        "        width=figsize[0] * 100, height=figsize[1] * 100\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "\"\"\"reducing.py\n",
        "Author: Kirgsn, 2018\n",
        "\"\"\"\n",
        "from joblib import Parallel, delayed\n",
        "from fastprogress import master_bar, progress_bar\n",
        "\n",
        "def measure_time_mem(func):\n",
        "    def wrapped_reduce(self, df, *args, **kwargs):\n",
        "        # pre\n",
        "        mem_usage_orig = df.memory_usage().sum() / self.memory_scale_factor\n",
        "        start_time = time()\n",
        "        # exec\n",
        "        ret = func(self, df, *args, **kwargs)\n",
        "        # post\n",
        "        mem_usage_new = ret.memory_usage().sum() / self.memory_scale_factor\n",
        "        end_time = time()\n",
        "        print(f'reduced df from {mem_usage_orig:.4f} MB '\n",
        "              f'to {mem_usage_new:.4f} MB '\n",
        "              f'in {(end_time - start_time):.2f} seconds')\n",
        "        gc.collect()\n",
        "        return ret\n",
        "    return wrapped_reduce\n",
        "\n",
        "\n",
        "class Reducer:\n",
        "    \"\"\"\n",
        "    Class that takes a dict of increasingly big numpy datatypes to transform\n",
        "    the data of a pandas dataframe into, in order to save memory usage.\n",
        "    \"\"\"\n",
        "    memory_scale_factor = 1024**2  # memory in MB\n",
        "\n",
        "    def __init__(self, conv_table=None, use_categoricals=True, n_jobs=-1):\n",
        "        \"\"\"\n",
        "        :param conv_table: dict with np.dtypes-strings as keys\n",
        "        :param use_categoricals: Whether the new pandas dtype \"Categoricals\"\n",
        "                shall be used\n",
        "        :param n_jobs: Parallelization rate\n",
        "        \"\"\"\n",
        "\n",
        "        self.conversion_table = \\\n",
        "            conv_table or {'int': [np.int8, np.int16, np.int32, np.int64],\n",
        "                           'uint': [np.uint8, np.uint16, np.uint32, np.uint64],\n",
        "                           'float': [np.float32, ]}\n",
        "        self.null_int = {   np.int8:  pd.Int8Dtype,\n",
        "                            np.int16: pd.Int16Dtype,\n",
        "                            np.int32: pd.Int32Dtype,\n",
        "                            np.int64: pd.Int64Dtype,\n",
        "                            np.uint8: pd.UInt8Dtype,\n",
        "                            np.uint16:pd.UInt16Dtype,\n",
        "                            np.uint32:pd.UInt32Dtype,\n",
        "                            np.uint64:pd.UInt64Dtype}\n",
        "\n",
        "        self.use_categoricals = use_categoricals\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    def _type_candidates(self, k):\n",
        "        for c in self.conversion_table[k]:\n",
        "            i = np.iinfo(c) if 'int' in k else np.finfo(c)\n",
        "            yield c, i\n",
        "\n",
        "    @measure_time_mem\n",
        "    def reduce(self, df, verbose=False):\n",
        "        \"\"\"Takes a dataframe and returns it with all data transformed to the\n",
        "        smallest necessary types.\n",
        "\n",
        "        :param df: pandas dataframe\n",
        "        :param verbose: If True, outputs more information\n",
        "        :return: pandas dataframe with reduced data types\n",
        "        \"\"\"\n",
        "        ret_list = Parallel(n_jobs=self.n_jobs, max_nbytes=None)(progress_bar(list(delayed(self._reduce)\n",
        "                                                (df[c], c, verbose) for c in\n",
        "                                                df.columns)))\n",
        "        del df\n",
        "        gc.collect()\n",
        "        return pd.concat(ret_list, axis=1)\n",
        "\n",
        "    def _reduce(self, s, colname, verbose):\n",
        "        try:\n",
        "            isnull = False\n",
        "            # skip NaNs\n",
        "            if s.isnull().any():\n",
        "                isnull = True\n",
        "            # detect kind of type\n",
        "            coltype = s.dtype\n",
        "            if np.issubdtype(coltype, np.integer):\n",
        "                conv_key = 'int' if s.min() < 0 else 'uint'\n",
        "            elif np.issubdtype(coltype, np.floating):\n",
        "                conv_key = 'float'\n",
        "                asint = s.fillna(0).astype(np.int64)\n",
        "                result = (s - asint)\n",
        "                result = np.abs(result.sum())\n",
        "                if result < 0.01:\n",
        "                    conv_key = 'int' if s.min() < 0 else 'uint'\n",
        "            else:\n",
        "                if isinstance(coltype, object) and self.use_categoricals:\n",
        "                    # check for all-strings series\n",
        "                    if s.apply(lambda x: isinstance(x, str)).all():\n",
        "                        if verbose: print(f'convert {colname} to categorical')\n",
        "                        return s.astype('category')\n",
        "                if verbose: print(f'{colname} is {coltype} - Skip..')\n",
        "                return s\n",
        "            # find right candidate\n",
        "            for cand, cand_info in self._type_candidates(conv_key):\n",
        "                if s.max() <= cand_info.max and s.min() >= cand_info.min:\n",
        "                    if verbose: print(f'convert {colname} to {cand}')\n",
        "                    if isnull:\n",
        "                        return s.astype(self.null_int[cand]())\n",
        "                    else:\n",
        "                        return s.astype(cand)\n",
        "\n",
        "            # reaching this code is bad. Probably there are inf, or other high numbs\n",
        "            print(f\"WARNING: {colname} doesn't fit the grid with \\nmax: {s.max()} \"\n",
        "                f\"and \\nmin: {s.min()}\")\n",
        "            print('Dropping it..')\n",
        "        except Exception as ex:\n",
        "            print(f'Exception for {colname}: {ex}')\n",
        "            return s\n",
        "\n",
        "def reduce_mem_usage(df):\n",
        "  return Reducer().reduce(df)\n",
        "\n",
        "#====DataPrepper\n",
        "class DataPrepper:\n",
        "    def __init__(self):\n",
        "        self.val_df = None\n",
        "        self.train_df = None\n",
        "        self.items_phsm_df = None\n",
        "        self.rust_player_count_df = None\n",
        "        self.dataset: pd.DataFrame = None\n",
        "        self.columns_to_drop = [\n",
        "            'previewUrl', 'views', 'timeCreated', 'timeRefreshed', 'isAvailableOnStore', 'creatorName',\n",
        "            'appId',\n",
        "            'id', 'nameId','hasGlow', 'hasCutout','timeAccepted'] # 'hasGlow', 'hasCutout' - no gain, no splits\n",
        "        self.desired_column_order = ['date', 'price', 'volume', 'name', 'playerCount', 'supplyTotalEstimated',\n",
        "                                     'storePrice',\n",
        "                                     'glowRatio',  'cutoutRatio', 'hasGlowSights', 'facepunchSkin',\n",
        "                                     'itemType',\n",
        "                                     'itemCollection',\n",
        "                                     ]\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Loads self.items_phsm_df and self.rust_player_count_df from files.\n",
        "        \"\"\"\n",
        "        with open(ITEMS_PHSM_JSON if not TEST_MODE else ITEMS_PHSM_JSON_TEST, 'r') as f:\n",
        "            items_phsm = json.load(f)\n",
        "\n",
        "        with open(PLAYER_COUNT_JSON, 'r') as f:\n",
        "            rust_player_count_json = json.load(f)\n",
        "\n",
        "        items_phsm = [item for item in items_phsm if item['name'] not in ITEMS_TO_EXCLUDE]\n",
        "\n",
        "        phsm_records = self.unfold_phsm(items_phsm)\n",
        "\n",
        "        self.items_phsm_df = pd.DataFrame(phsm_records)\n",
        "\n",
        "        self.rust_player_count_df = pd.DataFrame(rust_player_count_json)\n",
        "\n",
        "        print(\"Loaded\")\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"\n",
        "        Prepares, merges data and assigns it to self.dataset\n",
        "        \"\"\"\n",
        "\n",
        "        self.prep_player_count()\n",
        "        self.prep_items_phsm()\n",
        "\n",
        "        merged_df = pd.merge(self.items_phsm_df, self.rust_player_count_df, on='date',\n",
        "                             how='left')\n",
        "\n",
        "        ordered_df = merged_df.reindex(columns=self.desired_column_order)\n",
        "\n",
        "        self.dataset = ordered_df\n",
        "\n",
        "    @staticmethod\n",
        "    def unfold_phsm(items_phsm):\n",
        "        phsm_records = []\n",
        "        for item in items_phsm:\n",
        "            for phsm_entry in item['phsm']:\n",
        "                record = {k: v for k, v in item.items() if k != 'phsm'}\n",
        "                record.update(phsm_entry)\n",
        "                phsm_records.append(record)\n",
        "        return phsm_records\n",
        "\n",
        "    def prep_player_count(self):\n",
        "        self.rust_player_count_df = self.rust_player_count_df.rename(columns={'Date': 'date'})\n",
        "        self.rust_player_count_df = self.rust_player_count_df.rename(columns={'Player_count': 'playerCount'})\n",
        "        self.rust_player_count_df['date'] = pd.to_datetime(self.rust_player_count_df['date'])\n",
        "\n",
        "        return self.rust_player_count_df\n",
        "\n",
        "    def prep_items_phsm(self):\n",
        "        self.items_phsm_df.rename(columns={'median': 'price'},inplace=True)\n",
        "        self.items_phsm_df['date'] = pd.to_datetime(self.items_phsm_df['date'])\n",
        "        self.items_phsm_df['timeAccepted'] = pd.to_datetime(self.items_phsm_df['timeAccepted'], errors='coerce')\n",
        "        self.items_phsm_df['date'] = pd.to_datetime(self.items_phsm_df['date'])\n",
        "        self.items_phsm_df.drop(columns=self.columns_to_drop,inplace=True)  # Delete unnecessary columns\n",
        "        self.items_phsm_df = self.items_phsm_df.sort_values(by=['name', 'date'])\n",
        "\n",
        "\n",
        "        self.items_phsm_df.reset_index(drop=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def add_features(dataset,change_original=False):\n",
        "        raise NotImplementedError(\"Run window with add_features implementation first\") #Add features is often changed so it's implemented in other window so I don't have to create new object every time i change it\n",
        "\n",
        "def getdata_dataset(x,name,showdata=False):\n",
        "  grouped=x.groupby('name')['price']\n",
        "  d={\n",
        "     'df size': x.shape[0],\n",
        "     'price mean': x['price'].mean(),\n",
        "     'price median': x['price'].median(),\n",
        "     'price std': x['price'].std(),\n",
        "\n",
        "     'price items mean mean': grouped.mean().mean(),\n",
        "     'price items mean median': grouped.mean().median(),\n",
        "     'price items median mean': grouped.median().mean(),\n",
        "     'price items median median': grouped.median().median(),\n",
        "\n",
        "     'price items std mean': grouped.std().mean(),\n",
        "     'price items std median': grouped.std().median(),\n",
        "\n",
        "       }\n",
        "  if showdata:\n",
        "    print(name)\n",
        "    for k,v in d.items():\n",
        "      print(k,':',round(v,2))\n",
        "  return d\n",
        "\n",
        "def printdata_dataset(X,X_test):\n",
        "  dict_x = getdata_dataset(X,\"Train data: \")\n",
        "  dict_xt = getdata_dataset(X_test,\"\\nTest data: \")\n",
        "\n",
        "  d_x,d_xt = list(dict_x.values()), list(dict_xt.values())\n",
        "  percent_diff = [(x - xt) / xt * 100 for x, xt in zip(d_x, d_xt)]\n",
        "\n",
        "  table = PrettyTable()\n",
        "  table.field_names = [\"Key\", \"Value X\", \"Value X_test\", \"percent_diff\"]\n",
        "\n",
        "  for i in range(len(d_x)):\n",
        "      table.add_row([list(dict_x.keys())[i], f\"{d_x[i]:.2f}\", f\"{d_xt[i]:.2f}\", f\"{percent_diff[i]:.2f}%\"])\n",
        "\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDtjDISSgSqA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Helpers 2, Def prepare_datasets\n",
        "def split_dataset(X, y, test_size):\n",
        "\n",
        "    X.sort_index(level='date', inplace=True)\n",
        "    y.sort_index(level='date', inplace=True)\n",
        "\n",
        "    split_index = int(len(X) * (1 - test_size))\n",
        "\n",
        "    train_idx, test_idx = np.arange(0, split_index), np.arange(split_index, len(X))\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def get_model_postfix(test_metrics,addidional_info=\"\"):\n",
        "  mae = test_metrics[test_metrics['Metric'] == 'MAE'].iloc[0, 1]    # Test dataset\n",
        "  mape = test_metrics[test_metrics['Metric'] == 'MAPE'].iloc[0, 1]  # Test dataset\n",
        "  median_ae = test_metrics[test_metrics['Metric'] == 'Median Absolute Error'].iloc[0, 2]  # Test dataset\n",
        "  nmape = test_metrics[test_metrics['Metric'] == 'MAPE'].iloc[0, 2] # Naive mape\n",
        "  return f\"NMAPE{round(nmape * 1000)}MAE{round(mae * 1000)}MedAE{round(median_ae * 1000)}MAPE{round(mape * 1000)}{addidional_info}\"\n",
        "\n",
        "def autosave_model(model,name=\"lgbm_af\",postfix=\"\"):\n",
        "  # DATASET_DATA - globally set contant with data about dataset\n",
        "  try:\n",
        "    folder_path=MODEL_SAVES_PATH\n",
        "    curr_time = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "    file_path = os.path.join(folder_path, f\"{name}_{DATASET_DATA}_{curr_time}_{postfix}.txt\")\n",
        "    model.save_model(file_path)\n",
        "  except Exception as e:\n",
        "    print(f\"Error saving model: {e}\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "def autosave_optimizer(opt):\n",
        "  try:\n",
        "    folder_path=OPT_SAVES_PATH\n",
        "    curr_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    file_path = os.path.join(folder_path, f\"bayesian_optimizer_TEST{TEST_MODE}_{curr_time}.txt\")\n",
        "    joblib.dump(opt, file_path)\n",
        "  except Exception as e:\n",
        "    print(f\"Error saving optimizer: {e}\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "def create_naive_prediction(X_test,keys,verbose=True):\n",
        "  \"\"\" keys - what column of X_test to use as prediction, for example price_lag1 \"\"\"\n",
        "  #if keys is None:\n",
        "  #  keys=['price_lag1','price_lag2','price_lag3','storePrice']\n",
        "  for key in keys:\n",
        "    try:\n",
        "      y_pred_naive = pd.Series(X_test[key].fillna(3).to_numpy(), index = X_test.index)  # there shouldn't be much nan's\n",
        "      if verbose:\n",
        "        print(f\"Created naive prediction from {key}\")\n",
        "    except KeyError:\n",
        "      continue\n",
        "    else:\n",
        "      break\n",
        "  if y_pred_naive is None:\n",
        "    raise RuntimeError(\"Assigning value to y_pred_naive failed. Check your X_test dataset. Checked keys: \"+str(keys))\n",
        "  return y_pred_naive\n",
        "\n",
        "#@title def eval_models\n",
        "\n",
        "def get_last_index_TSS(X,n_splits):\n",
        "    \"\"\" Last test index from TimeSeriesSplit was never used for learning, only for validation.\n",
        "        Returns that test index.\"\"\"\n",
        "    tscv = TimeSeriesSplit(n_splits)\n",
        "    tscv.split(X)\n",
        "    test_index=None\n",
        "    for train_index_tmp, test_index_tmp in tscv.split(X):\n",
        "        test_index=test_index_tmp\n",
        "    return test_index\n",
        "\n",
        "def eval_model(model,X,y,set_name,keys_naive):\n",
        "    \"\"\" Evaluates model and returns dataframe with metrics. \"\"\"\n",
        "    pred = model.predict(X)\n",
        "    pred_naive = create_naive_prediction(X,keys=keys_naive)\n",
        "\n",
        "    results = {\n",
        "      \"Metric\": [\"Accuracy\", \"RMSE\", \"MAE\", \"MAPE\", \"Max Error\", \"Median Absolute Error\"],\n",
        "    }\n",
        "\n",
        "    results[set_name] = calc_accuracy(pred, y, f\"{set_name} accuracy:\")\n",
        "    results[\"Naive\"] = calc_accuracy(pred_naive, y, \"Naive accuracy:\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "DATASET_DATA=\"\"\n",
        "def prepare_datasets(dp,target_window=1,target_lag=0,test_size=0.15,columns_to_drop=None):\n",
        "  # target window has to be also in windows_price in add_features\n",
        "  # TARGET_LAG == X means that rolling mean is rolled after X+1 days from data point. If TARGET_LAG==0, mean is rolled starting on next day after data point.\n",
        "  if columns_to_drop is None:\n",
        "    columns_to_drop = []\n",
        "\n",
        "  global DATASET_DATA\n",
        "  DATASET_DATA=f\"tw_{target_window}_tl{target_lag}\"\n",
        "\n",
        "  target_data = {'window':target_window,'lag':target_lag}\n",
        "  dataset = dp.dataset.copy()\n",
        "  dataset.set_index(['name', 'date'], inplace=True)\n",
        "  dataset = dp.add_features(dataset,target_data)\n",
        "\n",
        "  dataset.drop(columns=columns_to_drop,inplace=True)  # Drop less important features\n",
        "\n",
        "  X_whole = dataset.drop(columns=['target'])\n",
        "  y_whole = dataset[\"target\"]\n",
        "\n",
        "  # Fix indexes\n",
        "  y_whole.dropna(inplace=True)\n",
        "  X_whole = X_whole.loc[y_whole.index]\n",
        "\n",
        "  X, X_test, y, y_test = split_dataset(X_whole,y_whole,test_size=test_size)\n",
        "  del X_whole,y_whole\n",
        "  return X, X_test, y, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u3nV2luI0iLn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load\n",
        "\n",
        "dp = DataPrepper()\n",
        "dp.load_data()\n",
        "dp.preprocess_data()\n",
        "\n",
        "# reduce_mem_usage in other places fucks types up, doesn't give much and is slow\n",
        "dp.items_phsm_df= reduce_mem_usage(dp.items_phsm_df)\n",
        "dp.rust_player_count_df = reduce_mem_usage(dp.rust_player_count_df)\n",
        "\n",
        "display(dp.dataset.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Def add features\n",
        "def add_features(dataset, target_data):\n",
        "    target_window = target_data['window']\n",
        "    target_lag = target_data['lag']\n",
        "\n",
        "    to_interpolate = ['price', 'volume', 'playerCount']\n",
        "    bool_columns = []\n",
        "    int_columns = ['year', 'month', 'day', 'volume', 'playerCount', 'supplyTotalEstimated', 'weekday']\n",
        "    categorical_columns = ['itemType', 'itemCollection']\n",
        "\n",
        "    columns_to_keep = ['price', 'volume', 'playerCount', 'supplyTotalEstimated', 'storePrice', 'itemType', 'itemCollection']\n",
        "\n",
        "    dataset = dataset[columns_to_keep]\n",
        "    original_column_order = dataset.columns.tolist()\n",
        "\n",
        "    # Interpolating data\n",
        "    interpolated_data = dataset.groupby('name')[to_interpolate].apply(\n",
        "        lambda group: group.reset_index('name', drop=True).asfreq('D').interpolate(method='linear'))\n",
        "\n",
        "    not_interpolated_data = dataset.groupby('name')[dataset.columns.difference(to_interpolate)].apply(\n",
        "        lambda group: group.reset_index('name', drop=True).asfreq('D'))\n",
        "\n",
        "    dataset = pd.concat([interpolated_data, not_interpolated_data], axis=1)[original_column_order]\n",
        "\n",
        "    def compute_features(group):\n",
        "\n",
        "        lags_price = [1, 2, 3, 4, 5, 6, 7, 14, 21, 28, 35, 56]\n",
        "        lags_vol = [1, 2, 3, 7, 14, 21]\n",
        "        lags_player_count = [1, 7, 14, 21, 28]\n",
        "\n",
        "        windows_price = [3, 7, 14, 21, 56, 84]\n",
        "        windows_volume = [3, 7, 14, 21, 56]\n",
        "        windows_player_count = [7, 14, 21, 28, 56]\n",
        "        ewma_windows = [7, 14, 21, 30, 56]\n",
        "\n",
        "        features = {}\n",
        "\n",
        "        lag_type_col = [1, 7, 14, 28, 56]\n",
        "\n",
        "        for lag in lags_price:\n",
        "          features[f'price_lag{lag}'] = group['price'].shift(lag)\n",
        "\n",
        "        for lag in lags_vol:\n",
        "          features[f'vol_lag{lag}'] = group['volume'].shift(lag)\n",
        "\n",
        "        for lag in lags_player_count:\n",
        "          lag = lag + 1  # lag+1 to avoid data leakage with rolling\n",
        "          for window in windows_player_count:\n",
        "\n",
        "            if len(group) + lag >= window:  # Ensure enough data points for rolling\n",
        "              roll = group[['playerCount']]['playerCount'].shift(lag).rolling(window=window)\n",
        "              features[f'playerCount_roll_mean_{window}_lag_{lag - 1}'] = roll.mean()\n",
        "            else:\n",
        "              features[f'playerCount_roll_mean_{window}_lag_{lag - 1}'] = np.nan\n",
        "\n",
        "        for window in windows_price:\n",
        "          if len(group) >= window:  # Ensure enough data points for rolling\n",
        "              roll = group[['price']].shift(1).rolling(window=window)\n",
        "              features.update({\n",
        "                f'price_roll_mean_{window}': roll['price'].mean(),\n",
        "                f'price_roll_std_{window}': roll['price'].std(),\n",
        "                f'price_roll_var_{window}': roll['price'].var(),\n",
        "                f'price_roll_sum_{window}': roll['price'].sum(),\n",
        "              })\n",
        "          else:\n",
        "            features.update({\n",
        "                f'price_roll_mean_{window}': np.nan,\n",
        "                f'price_roll_std_{window}': np.nan,\n",
        "                f'price_roll_var_{window}': np.nan,\n",
        "                f'price_roll_sum_{window}': np.nan,\n",
        "            })\n",
        "\n",
        "        for window in windows_volume:\n",
        "          if len(group) >= window:  # Ensure enough data points for rolling\n",
        "              roll = group[['volume']].shift(1).rolling(window=window)\n",
        "              features.update({\n",
        "                f'vol_roll_mean_{window}': roll['volume'].mean(),\n",
        "              })\n",
        "          else:\n",
        "            features.update({\n",
        "                f'vol_roll_mean_{window}': np.nan,\n",
        "            })\n",
        "\n",
        "        item_type_group = group.groupby('itemType', observed=True)\n",
        "        for window in windows_price:\n",
        "            if len(group) >= window:  # Ensure enough data points for rolling\n",
        "                roll = item_type_group[['price', 'volume']].shift(1).rolling(window=window)\n",
        "                features[f'itemType_price_roll_mean_{window}'] = roll['price'].mean()\n",
        "                features[f'itemType_price_roll_std_{window}'] = roll['price'].std()\n",
        "                features[f'itemType_price_roll_var_{window}'] = roll['price'].var()\n",
        "                features[f'itemType_price_roll_sum_{window}'] = roll['price'].sum()\n",
        "            else:\n",
        "                features[f'itemType_price_roll_mean_{window}'] = np.nan\n",
        "                features[f'itemType_price_roll_std_{window}'] = np.nan\n",
        "                features[f'itemType_price_roll_var_{window}'] = np.nan\n",
        "                features[f'itemType_price_roll_sum_{window}'] = np.nan\n",
        "\n",
        "        collection_group = group.groupby('itemCollection', observed=True)\n",
        "        for window in windows_price:\n",
        "          if len(group) >= window:  # Ensure enough data points for rolling\n",
        "            roll = collection_group[['price', 'volume']].shift(1).rolling(window=window)\n",
        "            features.update({\n",
        "                f'collection_price_roll_mean_{window}': roll['price'].mean(),\n",
        "                f'collection_price_roll_std_{window}': roll['price'].std(),\n",
        "                f'collection_price_roll_var_{window}': roll['price'].var(),\n",
        "                f'collection_price_roll_sum_{window}': roll['price'].sum(),\n",
        "            })\n",
        "          else:\n",
        "            features.update({\n",
        "                f'collection_price_roll_mean_{window}': np.nan,\n",
        "                f'collection_price_roll_std_{window}': np.nan,\n",
        "                f'collection_price_roll_var_{window}': np.nan,\n",
        "                f'collection_price_roll_sum_{window}': np.nan,\n",
        "            })\n",
        "\n",
        "        collection_mean = collection_group[['price', 'volume']].shift(1).expanding().mean()\n",
        "        features['collection_price_mean'] = collection_mean['price']\n",
        "        features['collection_vol_mean'] = collection_mean['volume']\n",
        "\n",
        "        features['price_trend'] = np.arange(len(group)) * group['price'].shift(1).pct_change().fillna(0)\n",
        "        features['volume_trend'] = np.arange(len(group)) * group['volume'].shift(1).pct_change().fillna(0)\n",
        "\n",
        "        for window in ewma_windows:\n",
        "            features[f'price_ewma_{window}'] = group['price'].shift(1).ewm(span=window, adjust=False).mean()\n",
        "\n",
        "        _target_price_roll_mean = group[['price']].shift(1).rolling(window=target_window)['price'].mean()\n",
        "        features[\"target\"] = _target_price_roll_mean.shift(-target_window - 1).shift(-target_lag)\n",
        "\n",
        "        return pd.concat([group, pd.DataFrame(features, index=group.index)], axis=1)\n",
        "\n",
        "    dataset = dataset.groupby('name', group_keys=False).apply(compute_features)\n",
        "\n",
        "    dates = dataset.index.get_level_values('date')\n",
        "    dataset['year'] = dates.year\n",
        "    dataset['month'] = dates.month\n",
        "    dataset['day'] = dates.day\n",
        "    dataset['weekday'] = dates.weekday\n",
        "    #dataset['is_weekend'] = (dataset['weekday'] >= 5)\n",
        "    dataset['d_from_nyear'] = (dates - pd.to_datetime(dates.year.astype(str) + '-01-01')).days\n",
        "    dataset['d_to_june'] = (pd.to_datetime(dates.year.astype(str) + '-06-01') - dates).days\n",
        "\n",
        "    dataset[bool_columns] = dataset[bool_columns].astype(bool)\n",
        "    dataset[int_columns] = dataset[int_columns].fillna(0).astype(int)\n",
        "    dataset[categorical_columns] = dataset[categorical_columns].astype('category')\n",
        "\n",
        "    dataset.dropna(subset=['itemType'], inplace=True)\n",
        "\n",
        "    return dataset\n",
        "dp.add_features = add_features"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1Gh_K9sptJSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCDtpUpQbSgK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Features to drop\n",
        "columns_to_drop = ['collection_price_roll_std_84',\n",
        "                   'price_lag6',  'itemType_price_roll_std_14',\n",
        "                   'price_lag3',  'itemType_price_roll_var_84',\n",
        "                   'itemType_price_roll_var_7',\n",
        "                   'collection_price_roll_sum_84',\n",
        "                   'collection_price_roll_var_84',\n",
        "                   'collection_price_roll_mean_84',\n",
        "                   'collection_price_roll_sum_56',\n",
        "                   'collection_price_roll_std_56',\n",
        "                   'vol_lag3',  'price_lag2',\n",
        "                   'weekday',  'price_lag4',\n",
        "                   'collection_price_roll_var_56',\n",
        "                   'price_roll_var_56',\n",
        "                   'collection_price_roll_mean_56',\n",
        "                   'collection_price_roll_sum_21',\n",
        "                   'itemType_price_roll_std_3',\n",
        "                   'itemType_price_roll_var_3',\n",
        "                   'itemType_price_roll_std_7',\n",
        "                   'itemType_price_roll_var_14',\n",
        "                   'vol_lag21',  'vol_lag7',\n",
        "                   'collection_price_roll_std_3',\n",
        "                   'collection_price_roll_std_7',\n",
        "                   'collection_price_roll_var_7',\n",
        "                   'collection_price_roll_sum_7',\n",
        "                   'collection_price_roll_mean_14',\n",
        "                   'collection_price_roll_std_14',\n",
        "                   'collection_price_roll_var_14',\n",
        "                   'collection_price_roll_sum_14',\n",
        "                   'collection_price_roll_mean_21',\n",
        "                   'collection_price_roll_std_21',\n",
        "                   'collection_price_roll_var_21']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQfWoujYIM8A"
      },
      "outputs": [],
      "source": [
        "X, X_test, y, y_test = prepare_datasets(dp,7,28,columns_to_drop=columns_to_drop)\n",
        "#printdata_dataset(X,X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optuna config\n",
        "OPTUNA_N_WARMUP_STEPS = 20\n",
        "STUDY_NAME=f\"optuna_study_v3\"\n",
        "STORAGE_NAME = f\"sqlite:///{STUDY_NAME}.db\"\n",
        "\n",
        "scoring = make_scorer(mean_absolute_error, greater_is_better=False)\n",
        "cv_strategy = list(TimeSeriesSplit(N_SPLITS).split(X))\n",
        "\n",
        "OPTUNA_EARLY_STOPPING = 80"
      ],
      "metadata": {
        "id": "LeYjwOO-fisx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w3y6XrO2pzqs"
      },
      "outputs": [],
      "source": [
        "#@title def Optuna functions\n",
        "MAIN_METRIC='l1'  # alias mae probably doesnt work in optuna\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'boosting_type': 'gbdt',\n",
        "        'objective': MAIN_METRIC,\n",
        "        'metric': MAIN_METRIC,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.5,log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 60, 800),\n",
        "        'max_depth': trial.suggest_int('max_depth', 20, 200),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 0.95),\n",
        "        'subsample_freq': trial.suggest_int('subsample_freq', 3, 24),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.7),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-7, 100.0,log=True),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 0.0001,log=True),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 32, 128),\n",
        "        'min_split_gain': trial.suggest_categorical('min_split_gain', [0.00005,0.0001,0.001,0.005,0.01,0.1,0.5,2,4,10]),\n",
        "        'max_bin': trial.suggest_int('max_bin', 2512, 8096),\n",
        "        'seed': 40,\n",
        "        'num_threads': -1,\n",
        "        'device': 'gpu' if gpu_available else 'cpu',\n",
        "        'gpu_platform_id': 0,\n",
        "        'gpu_device_id': 0,\n",
        "        'verbose': -1\n",
        "    } #Nranges\n",
        "\n",
        "    cv_results = lgb.cv(\n",
        "        param,\n",
        "        lgb.Dataset(X, label=y, free_raw_data=False),\n",
        "        folds=cv_strategy,\n",
        "        num_boost_round=800,\n",
        "        return_cvbooster=False,\n",
        "        callbacks=[LightGBMPruningCallback(trial, MAIN_METRIC),lgb.log_evaluation(period=100),\n",
        "              lgb.early_stopping(stopping_rounds=OPTUNA_EARLY_STOPPING, min_delta=0.001)]\n",
        "    )\n",
        "\n",
        "    best_score = min(cv_results[f'valid {main-metric}-mean'])\n",
        "    gc.collect()\n",
        "    return best_score\n",
        "\n",
        "def print_results(study):\n",
        "  print('='*10)\n",
        "  print(f\"ITERATION {iter}\\nBest parameters:\")\n",
        "  pprint.pprint(study.best_params)\n",
        "  print(f\"Best MAE score: {study.best_value:.3f}\")\n",
        "  print('='*10)\n",
        "\n",
        "def configure_storage(study,study_name,storage_name):\n",
        "  rdb_storage = optuna.storages.RDBStorage(url=storage_name)\n",
        "  study._storage = rdb_storage\n",
        "  study.study_name = study_name\n",
        "\n",
        "def save_study(study_name,name):\n",
        "  destination = \"/content/drive/MyDrive/SMF_files/optuna_saves/\"\n",
        "  os.system(f\"cp {study_name}.db {destination}{name}\")\n",
        "\n",
        "def optuna_automated(test_postfix,iters=1,n_trials=100,iter_timeout=60*60*1):\n",
        "  for i in range(iters):\n",
        "    iter = i+1\n",
        "    print(f\"Starting iteration {iter}:\")\n",
        "    try:\n",
        "      study = optuna.create_study(direction='minimize',storage=STORAGE_NAME,study_name=STUDY_NAME, load_if_exists=True,pruner=optuna.pruners.MedianPruner(n_warmup_steps=OPTUNA_N_WARMUP_STEPS))\n",
        "\n",
        "      configure_storage(study,STUDY_NAME,STORAGE_NAME)\n",
        "\n",
        "      study.optimize(objective, n_trials=n_trials, timeout=iter_timeout, show_progress_bar=True,gc_after_trial=True)\n",
        "\n",
        "      save_study(STUDY_NAME,f\"study_{iter}.db\"+test_postfix)\n",
        "\n",
        "      print_results(study)\n",
        "    except Exception as e:\n",
        "      print('='*10+f\"An error occurred during iteration {iter}: {e}\")\n",
        "      continue\n",
        "  return study\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VMvZ347-FIxM"
      },
      "outputs": [],
      "source": [
        "test_postfix=\"unknown\"\n",
        "study = optuna_automated(test_postfix,iters=10,n_trials=300,iter_timeout=60*60*1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z2yXhfV_hiKq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Optuna results\n",
        "\n",
        "display(optuna.visualization.plot_optimization_history(study))\n",
        "display(optuna.visualization.plot_parallel_coordinate(study))\n",
        "display(optuna.visualization.plot_slice(study))\n",
        "display(optuna.visualization.plot_param_importances(study))\n",
        "display(optuna.importance.get_param_importances(study,normalize=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgHZHmT4z7wu"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/model.txt'\n",
        "model = lgb.Booster(model_file=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BQWoOSO4kqB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title params\n",
        "const_params={\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'mae',\n",
        "    'metric': ['mape','mae'],\n",
        "    'seed': 42,\n",
        "    'num_threads':-1,   # 5K dart rounds x3, 4 threads are the best, 30% faster than 8 or -1 and 8% faster than second fastest number score\n",
        "    'device': 'gpu' if gpu_available else 'cpu',\n",
        "    'gpu_platform_id': 0,\n",
        "    'gpu_device_id': 0,\n",
        "    'verbose': -1,\n",
        "    'num_iterations': 1000,               # num_iterations\n",
        "    }\n",
        "model_params=const_params.copy()\n",
        "\n",
        "model_params.update({\n",
        "    'colsample_bytree': 0.8455589519488225,\n",
        "    'learning_rate': 0.24539178594231917,\n",
        "    'max_bin': 4376,\n",
        "    'max_depth': 87,\n",
        "    'min_child_samples': 107,\n",
        "    'min_split_gain': 0.0001,\n",
        "    'num_leaves': 30,\n",
        "    'reg_alpha': 7.469125945743011e-08,\n",
        "    'reg_lambda': 0.004114222327399969,\n",
        "    'subsample': 0.7815644514881227,\n",
        "    'subsample_freq': 2})\n",
        "\n",
        "## !!! Remember to check n-estimators/num_boost_round\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_params.update(study.best_params)"
      ],
      "metadata": {
        "id": "OIqEZZonhi6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_98q2TI50iSV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Def learnCV\n",
        "NAIVE_KEYS=['price_roll_mean_7','price_lag1','price_lag2','price_lag3','storePrice']\n",
        "def learnCV(model_params,X,y,n_splits,stopping_rounds):\n",
        "  \"\"\" returns model and tuple with all training data from all splits and all validation (test) data from all splits and naive predictions for all splits\"\"\"\n",
        "  all_y_pred_train,all_y_train = [],[]\n",
        "  all_y_pred_test,all_y_test = [],[]\n",
        "  all_y_pred_naive = []\n",
        "  tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "  for train_index, test_index in tscv.split(X):\n",
        "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "      train_lgb_dataset = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
        "      test_lgb_dataset = lgb.Dataset(X_test, label=y_test, free_raw_data=False)\n",
        "\n",
        "      model = lgb.train(\n",
        "          model_params,\n",
        "          train_lgb_dataset,\n",
        "          valid_sets=[test_lgb_dataset],\n",
        "          valid_names=['test'],\n",
        "          callbacks=[\n",
        "              lgb.log_evaluation(period=100),\n",
        "              lgb.early_stopping(stopping_rounds=stopping_rounds)#, min_delta=[0.0008,0.001])\n",
        "          ]\n",
        "      )\n",
        "\n",
        "      y_pred_train = pd.Series(model.predict(X_train, num_iteration=model.best_iteration), index=X_train.index)\n",
        "      y_pred_test = pd.Series(model.predict(X_test, num_iteration=model.best_iteration), index=X_test.index)\n",
        "\n",
        "      y_pred_naive = create_naive_prediction(X_test,keys=NAIVE_KEYS,verbose=True)\n",
        "\n",
        "      all_y_pred_train.append(y_pred_train)\n",
        "      all_y_train.append(y_train)\n",
        "      all_y_pred_test.append(y_pred_test)\n",
        "      all_y_test.append(y_test)\n",
        "      all_y_pred_naive.append(y_pred_naive)\n",
        "\n",
        "  del X_train, X_test,y_train, y_test,train_lgb_dataset,test_lgb_dataset, y_pred_train,y_pred_test,y_pred_naive\n",
        "  gc.collect()\n",
        "\n",
        "  y_pred_train_concat = pd.concat(all_y_pred_train)\n",
        "  y_train_concat = pd.concat(all_y_train)\n",
        "  y_pred_test_concat = pd.concat(all_y_pred_test)\n",
        "  y_test_concat = pd.concat(all_y_test)\n",
        "  y_pred_naive_concat = pd.concat(all_y_pred_naive)\n",
        "  return model,(y_pred_train_concat, y_train_concat, y_pred_test_concat, y_test_concat, y_pred_naive_concat)  # all training data from all splits and all validation (test) data from all splits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "II9oV3xyMwW0"
      },
      "outputs": [],
      "source": [
        "additional_info=\"\"\n",
        "\n",
        "stopping_rounds = 100\n",
        "model,datasets = learnCV(model_params,X, y, N_SPLITS,stopping_rounds)\n",
        "learning_summary=get_learning_summary(*datasets, label=\"mae\")\n",
        "display(learning_summary)\n",
        "y_pred_train_concat, y_train_concat, y_pred_test_concat, y_test_concat, y_pred_naive_concat= datasets\n",
        "\n",
        "if not TEST_MODE:\n",
        "  metrics_test = eval_model(model,X_test,y_test,\"Test\",NAIVE_KEYS)\n",
        "  print('Test metrics: ')\n",
        "  display(metrics_test)\n",
        "  autosave_model(model,postfix=get_model_postfix(metrics_test,additional_info))\n",
        "\n",
        "valid_idx = get_last_index_TSS(X,N_SPLITS)\n",
        "X_valid = X.iloc[valid_idx]\n",
        "y_valid = y.iloc[valid_idx]\n",
        "\n",
        "print(get_model_postfix(metrics_test,additional_info))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ5wZBnqWP1-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "display(metrics_test)\n",
        "metrics_valid = eval_model(model,X_valid,y_valid,\"Valid\",NAIVE_KEYS)\n",
        "display(metrics_valid)\n",
        "metrics_train = eval_model(model,X,y,\"Train\",NAIVE_KEYS)\n",
        "display(metrics_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_test = eval_model(model,X_test,y_test,\"Test\",NAIVE_KEYS)\n",
        "display(metrics_test)"
      ],
      "metadata": {
        "id": "rS-ziiZL-cHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEsvNX7Tsa80"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXbn3Hqe8L5_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "trim=0\n",
        "print_importances(model,trim,True,figsize=(10, 18),importance_type='gain')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Analyzer\n",
        "\n",
        "class Analyzer():\n",
        "  def __init__(self,X,y,model=None,show=False):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.model = model\n",
        "    self.selected_columns = ['volume', 'playerCount',\n",
        "                    'supplyTotalEstimated', 'storePrice',\n",
        "                    'itemType', 'itemCollection']\n",
        "    self.create_dataset()\n",
        "    self.group_data()\n",
        "    self.add_info(show=show)\n",
        "\n",
        "  def create_dataset(self):\n",
        "    self.ds = self.X[self.selected_columns].copy()\n",
        "    self.ds['target'] = self.y\n",
        "    self.ds['pred'] = model.predict(self.X)\n",
        "\n",
        "    self.ds['itemAE'] = (self.ds['target'] - self.ds['pred']).abs()\n",
        "    self.ds['itemAPE'] = self.ds['itemAE'] / self.ds['target'].abs()\n",
        "\n",
        "  def group_data(self):\n",
        "    self.grouped = self.ds.groupby('name').agg(\n",
        "      itemType=('itemType', 'first'),\n",
        "      itemCollection=('itemCollection', 'first'),\n",
        "\n",
        "      volume=('volume', 'mean'),\n",
        "      playerCount=('playerCount', 'mean'),\n",
        "      supplyTotalEstimated=('supplyTotalEstimated', 'mean'),\n",
        "      storePrice=('storePrice', 'mean'),\n",
        "\n",
        "      itemMAE=('itemAE', 'mean'),\n",
        "      itemMedAE=('itemAE', 'median'),\n",
        "      itemMAPE=('itemAPE', 'mean'),\n",
        "      size=('target', 'size')\n",
        "    )\n",
        "\n",
        "  def add_info(self,show=False):\n",
        "    self.item_counts = self.ds.groupby(['name']).size().reset_index(name='count')\n",
        "    self.name_list = self.item_counts['count'].tolist()\n",
        "\n",
        "    if show:\n",
        "      print(f\"X shape: {self.X.shape} y shape: {self.y.shape}\")\n",
        "      display(self.item_counts)\n",
        "\n",
        "  def get_item_data(self,item_name):\n",
        "    if item_name not in self.ds.index.get_level_values('name'):\n",
        "      print(f\"{item_name} is not in the given data\")\n",
        "      return None\n",
        "    return self.ds.xs(item_name, level='name', drop_level=True)\n",
        "\n",
        "  def analyze(self):\n",
        "    ds = self.ds\n",
        "\n",
        "  def plot(self,item_name,plot_name=None):\n",
        "    if plot_name is None:\n",
        "      plot_name = f\"plot {item_name}\"\n",
        "    item_data = self.get_item_data(item_name)\n",
        "    if item_data is None:\n",
        "      return\n",
        "    plot_pricehistory([item_data['pred'],item_data['target']],['pred','target'],plot_name)\n"
      ],
      "metadata": {
        "id": "UBNc6BJhiDhu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = Analyzer(X,y,model,show=False)"
      ],
      "metadata": {
        "id": "aYQ7bKkPiEQw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer_test = Analyzer(X_test,y_test,model,show=False)"
      ],
      "metadata": {
        "id": "aNRrCgz6jfiL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "CGTrwcmxi86f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_name=\"Whiteout Kilt\"\n",
        "analyzer.plot(item_name)\n",
        "analyzer_test.plot(item_name)\n"
      ],
      "metadata": {
        "id": "7ryG2o4_iwLd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_name=\"Forest Raiders Pants\"\n",
        "analyzer.plot(item_name)\n",
        "analyzer_test.plot(item_name)\n"
      ],
      "metadata": {
        "id": "jQS7XnK5iEbk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(analyzer.get_item_data(\"Forest Raiders Pants\"))\n",
        "display(analyzer_test.get_item_data(\"Forest Raiders Pants\"))\n",
        "display(analyzer.get_item_data(\"Blackout Kilt\"))\n",
        "display(analyzer_test.get_item_data(\"Blackout Kilt\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "twEvK1qBou2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaZch1suzFkB"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOjFHUSNARD48O2KofxeJ0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}